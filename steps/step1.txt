================================================================
CHECKLIT – PODSUMOWANIE ETAP 1: SETUP PROJEKTU
================================================================
Data: luty 2025
Stan: ✅ Backend działa | ✅ Frontend działa

----------------------------------------------------------------
CO ZBUDOWALIŚMY
----------------------------------------------------------------

Pełną strukturę projektu "checkLit" – platformy do analizy
autentyczności i stylu tekstów literackich. Projekt składa się
z backendu w Pythonie i frontendu w React.js.

----------------------------------------------------------------
STRUKTURA PROJEKTU
----------------------------------------------------------------

checkLit/
├── backend/
│   ├── app/
│   │   ├── main.py              # Punkt wejścia FastAPI, CORS, routing
│   │   ├── database.py          # Konfiguracja SQLite + SQLAlchemy
│   │   ├── models.py            # Model bazy danych (tabela: analyses)
│   │   ├── schemas.py           # Schematy Pydantic (request/response)
│   │   ├── routers/
│   │   │   └── analysis.py      # 5 endpointów REST API
│   │   └── services/
│   │       ├── stylometry.py    # Analiza stylometryczna
│   │       ├── nlp_service.py   # Analiza jakości językowej
│   │       └── ai_detector.py   # Detekcja AI (Herbert + perplexity)
│   ├── tests/
│   │   └── test_analysis.py     # Testy jednostkowe + integracyjne
│   └── requirements.txt
├── frontend/
│   ├── src/
│   │   ├── App.jsx              # Router, layout
│   │   ├── api/axios.js         # Klient HTTP
│   │   ├── components/
│   │   │   └── Navbar.jsx       # Nawigacja
│   │   └── pages/
│   │       ├── Home.jsx         # Strona główna / landing
│   │       ├── Analyze.jsx      # Formularz analizy tekstu
│   │       ├── Results.jsx      # Wyniki z wykresami
│   │       ├── History.jsx      # Historia analiz
│   │       ├── Compare.jsx      # Porównanie dwóch tekstów
│   │       └── About.jsx        # O platformie / tech stack
│   ├── package.json
│   ├── vite.config.js
│   └── tailwind.config.js
└── README.md

----------------------------------------------------------------
TECHNOLOGIE I DLACZEGO
----------------------------------------------------------------

BACKEND:
  Python 3.11.9
    → Wersja "złotego standardu" dla ML/AI – pełne wsparcie
      wheel'ami dla PyTorch, brak problemów z kompilacją C++.
      (Próbowaliśmy 3.13/3.14 – za nowe, brak wheel'i dla torch)

  FastAPI
    → Szybki, nowoczesny framework REST API.
      Auto-generuje dokumentację Swagger pod /docs.
      Idealny do projektów akademickich – czytelny kod.

  SQLite + SQLAlchemy
    → Zero konfiguracji – baza danych jako plik .db.
      Idealna do pracy inżynierskiej, nie wymaga serwera.

  PyTorch 2.4.1 + Transformers 4.44.2
    → Silnik dla modelu detekcji AI (Herbert).
      ~2.5GB instalacji, ale działa w pełni lokalnie, bez API.

  Pytest
    → Testy jednostkowe i integracyjne.
      Wymagane przez opis pracy ("testy weryfikujące skuteczność").

FRONTEND:
  React.js 18 + Vite
    → Wymóg z opisu pracy inżynierskiej.
      Vite zamiast Create React App – szybszy, nowocześniejszy.

  Tailwind CSS
    → Stylowanie bez pisania CSS od zera.
      Gotowe klasy utility, responsywność out-of-the-box.

  Recharts
    → Wykresy: radar chart (profil stylometryczny),
      bar chart (n-gramy), progress bars (metryki AI).

  Axios
    → Klient HTTP do komunikacji z FastAPI.
      Obsługa błędów przez interceptory.

  React Router DOM
    → Routing między stronami (SPA).

----------------------------------------------------------------
MODEL DETEKCJI AI – DLACZEGO HERBERT
----------------------------------------------------------------

Pierwotnie planowaliśmy roberta-base-openai-detector, ale:
  ✗ Trenowany na tekstach GPT-2 (2019) – przestarzały
  ✗ Słabo wykrywa GPT-4, Claude, Gemini
  ✗ Trenowany głównie na angielskim

Wybraliśmy allegro/herbert-base-cased + perplexity detection:
  ✓ Polski model BERT od Allegro – rozumie język polski
  ✓ Metoda perplexity niezależna od konkretnego modelu AI
  ✓ Naukowo uzasadniona: teksty AI mają niską perplexity
    (model "nie jest zaskoczony" kolejnym słowem)
  ✓ Działa na CPU – nie wymaga GPU
  ✓ ~440MB – mniejszy niż alternatywy
  ✓ Lazy loading – pobiera się przy pierwszym zapytaniu,
    nie przy starcie serwera

Progi perplexity (wyznaczone empirycznie):
  perplexity < 60  → prawdopodobnie AI   (ai_prob ~0.85-0.97)
  perplexity 60-120 → strefa szara       (interpolacja liniowa)
  perplexity > 120 → prawdopodobnie człowiek (ai_prob ~0.03-0.15)

----------------------------------------------------------------
ZAIMPLEMENTOWANE FUNKCJONALNOŚCI
----------------------------------------------------------------

  ✅ Analiza detekcji AI (perplexity + Herbert)
  ✅ Analiza stylometryczna:
       - TTR (Type-Token Ratio)
       - Średnia długość zdania
       - Gęstość leksykalna
       - Entropia Shannona
       - Bogactwo słownikowe
       - Top bigramy (n-gramy)
  ✅ Analiza jakości językowej:
       - Flesch Reading Ease
       - Średnia długość słowa
       - Gęstość interpunkcji
  ✅ Zapis wyników do bazy SQLite
  ✅ Historia analiz (GET /api/history)
  ✅ Porównanie dwóch tekstów (/compare)
  ✅ Testy jednostkowe i integracyjne (pytest)
  ✅ Dokumentacja API (Swagger pod /docs)
  ✅ Upload pliku .txt
  ✅ Wykresy: radar, słupkowy, progress bars

----------------------------------------------------------------
ENDPOINTY API
----------------------------------------------------------------

  POST   /api/analyze          → Analiza tekstu
  GET    /api/results/{id}     → Pobierz wyniki po ID
  GET    /api/history          → Lista poprzednich analiz
  POST   /api/compare          → Porównanie dwóch tekstów
  DELETE /api/history/{id}     → Usuń analizę

----------------------------------------------------------------
JAK URUCHOMIĆ
----------------------------------------------------------------

Terminal 1 – Backend:
  cd checkLit/backend
  venv\Scripts\activate
  uvicorn app.main:app --reload
  → http://localhost:8000
  → http://localhost:8000/docs (Swagger)

Terminal 2 – Frontend:
  cd checkLit/frontend
  npm run dev
  → http://localhost:5173

----------------------------------------------------------------
PROBLEMY NAPOTKANE I ROZWIĄZANIA
----------------------------------------------------------------

Problem 1: spaCy nie instaluje się na Windows
  Przyczyna: brak kompilatora C++ (Visual Studio Build Tools)
  Rozwiązanie: usunięto spaCy i NLTK z requirements.txt
  (nie były używane w kodzie – nasze serwisy używają stdlib)

Problem 2: torch==2.3.0 nie ma wheel dla Python 3.13/3.14
  Przyczyna: za nowa wersja Pythona
  Rozwiązanie: zainstalowano Python 3.11.9 (py install 3.11)
  i zaktualizowano torch do 2.4.1

Problem 3: konflikt starego py.exe (Python Launcher)
  Przyczyna: zainstalowany był legacy Python Launcher
  Rozwiązanie: odinstalowanie Python Launcher z Installed Apps

----------------------------------------------------------------
CO DALEJ (ETAP 2)
----------------------------------------------------------------

  → Podpięcie frontendu do działającego API
  → Testy end-to-end z prawdziwymi tekstami literackimi
  → Kalibracja progów perplexity na polskich tekstach
  → Eksport raportu (JSON/PDF)
  → Pisanie rozdziałów pracy inżynierskiej

================================================================
